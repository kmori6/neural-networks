dataset:
  train_json_path: ???
  valid_json_path: ???
  test_json_path: ???

tokenizer:
  model_path: ???

model:
  vocab_size: 8000
  d_model: 512
  num_heads: 8
  d_ff: 2048
  num_layers: 6
  dropout_rate: 0.1
  pad_token_id: 0
  bos_token_id: 2
  eos_token_id: 3
  label_smoothing: 0.1

dataloader:
  train:
    batch_size: 32
    shuffle: true
    num_workers: 2
    pin_memory: true
    drop_last: true
  valid:
    batch_size: 32
    shuffle: false
    num_workers: 2
    pin_memory: true
    drop_last: false

trainer:
  optimizer:
    lr: 1e-4
    weight_decay: 1e-3
  scheduler:
    warmup_steps: 25000
  epochs: 50
  grad_accum_steps: 4
  max_norm: 5.0
  log_steps: 100
  out_dir: ???
  checkpoint_path:

decode:
  model_path: ???
  out_dir: ???
  beam_size: 4

hydra:
  run:
    dir: ./
  output_subdir: null
  job_logging:
    version: 1
    formatters:
      simple:
        format: '%(asctime)s %(filename)s:%(lineno)d %(levelname)s: %(message)s'
    handlers:
      console:
        class: logging.StreamHandler
        formatter: simple
        stream: ext://sys.stdout
    root:
      handlers: [console]
    disable_existing_loggers: false
